# adv-attack
 
AAAI 2018 Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing their Input Gradients https://github.com/dtak/adversarial-robustness-public

CVPR 2018 On the Robustness of Semantic Segmentation Models to Adversarial Attacks https://github.com/hmph/adversarial-attacks

CVPR 2018 Defense against Universal Adversarial Perturbations https://github.com/LTS4/universal

CVPR 2018 Boosting Adversarial Attacks with Momentum https://github.com/dongyp13/Non-Targeted-Adversarial-Attacks

CVPR 2018 Art of singular vectors and universal adversarial perturbations https://github.com/KhrulkovV/singular-fool 

CVPR 2018 Defense against Adversarial Attacks Using High-Level Representation Guided Denoiser https://github.com/lfz/Guided-Denoise

CVPR 2018 Generative Adversarial Perturbations https://github.com/OmidPoursaeed/Generative_Adversarial_Perturbations

ICLR 2018 Cascade Adversarial Training Regularized with a Unified Embedding https://github.com/taesikna/cascade_adv_training 

ICML & NIPS 2017 workshop? Provable defenses against adversarial examples via the convex outer adversarial polytope Scaling provable adversarial defenses https://github.com/locuslab/convex_adversarial 

ICLR 2018 Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality https://github.com/xingjunm/lid_adversarial_subspace_detection 

ICLR 2018 Countering Adversarial Images Using Input Transformations https://github.com/facebookresearch/adversarial_image_defenses 

ICLR 2018 Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models https://github.com/greentfrapp/boundary-attack https://github.com/bethgelab/foolbox/blob/master/foolbox/attacks/boundary_attack.py 

ICLR 2018 Decision Boundary Analysis of Adversarial Examples https://github.com/sunblaze-ucb/decision-boundaries 

ICLR 2018 Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models https://github.com/kabkabm/defensegan 

ICLR 2018 Ensemble Adversarial Training: Attacks and Defenses https://github.com/ftramer/ensemble-adv-training 

ICLR 2018 Generating Natural Adversarial Examples https://github.com/zhengliz/natural-adversary

ICLR 2018 Mitigating Adversarial Effects Through Randomization https://github.com/cihangxie/NIPS2017_adv_challenge_defense 

ICLR 2018 Spatially Transformed Adversarial Examples https://github.com/rakutentech/stAdv 

ICLR 2018 Stochastic activation pruning for robust adversarial defense https://github.com/anishathalye/obfuscated-gradients 

ICLR 2018 Thermometer Encoding: One Hot Way To Resist Adversarial Examples https://github.com/Flag-C/ThermometerEncoding  https://github.com/anishathalye/obfuscated-gradients/tree/master/thermometer 

ICLR 2018 Towards Deep Learning Models Resistant to Adversarial Attacks https://github.com/karandwivedi42/adversarial 

ICML 2018 Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples (Amazingly Good, kicking-face-paper, Need-to-Read Carefully) https://github.com/anishathalye/obfuscated-gradients 
